{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_TvE_L1CYJs"
      },
      "source": [
        "# Text Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Jdr-fjCZeU"
      },
      "source": [
        "---\n",
        "## Content\n",
        "1) **Project Overview**\n",
        "\n",
        "2) **Import Dataset**\n",
        "- In `.parquet`format\n",
        "\n",
        "3) **Text Preprocessing**\n",
        "- Tokenize the text data and convert it to sequences\n",
        "- Pad or truncate sequences to ensure uniform input length.\n",
        "- Handle special tokens (e.g., start-of-sequence `<sos>` and end-of-sequence `<eos>`).\n",
        "\n",
        "4) **Model Development**\n",
        "- Build a Seq2Seq model in TensorFlow with the following components:\n",
        "    - Encoder (RNN/LSTM/GRU).\n",
        "    - Decoder with attention mechanism.\n",
        "    - Attention layer to enhance summary quality.\n",
        "\n",
        "5) **Training**\n",
        "- Split the dataset\n",
        "    - %80 train data\n",
        "    - %10 validation data\n",
        "    - %10 test data\n",
        "- Train the model on the training set\n",
        "- Monitor performance using the validation set\n",
        "- Adjust hyperparameters as necessary.\n",
        "\n",
        "6) **Evaluation**\n",
        "- Use the test set to generate summaries.\n",
        "- Evaluate the generated summaries using the ROUGE metric.\n",
        "\n",
        "7) **Analysis**\n",
        "- Compare generated summaries to reference summaries and discuss performance.\n",
        "- Suggest potential improvements or extensions for better results.\n",
        "\n",
        "8) **Contributors**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW8Qpr3TCf3P"
      },
      "source": [
        "---\n",
        "## Project Overview\n",
        "This project focuses on developing a text summarization system for news articles using Sequence-to-Sequence (Seq2Seq) models enhanced with attention mechanisms. By utilizing a custom dataset of news content, the model is trained to generate concise, coherent, and informative summaries that capture the key points of each article.\n",
        "\n",
        "The Seq2Seq architecture, paired with attention, allows the model to dynamically focus on relevant parts of the input text during the decoding process, improving the quality and accuracy of the summaries. This approach addresses the challenge of long and complex news articles by effectively reducing redundancy and preserving critical information.\n",
        "\n",
        "The project includes dataset preprocessing, model training, and evaluation using metrics such as ROUGE, with the goal of producing high-quality, human-like summaries. This work aims to contribute to automated news aggregation, efficient information retrieval, and content generation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PjjEWoNCmfK"
      },
      "source": [
        "---\n",
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z32Nb9byCyq7"
      },
      "source": [
        "Since we will work on Google Colab, first mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWDqs0ghDBu4",
        "outputId": "19a3e092-d141-4b08-e4e9-cc3ccb8be99a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XervwGNrCEcF",
        "outputId": "c951e11a-bf2e-4e2c-f0c2-07d0528b78ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are currently in /content directory\n",
            " ds1.parquet\t   mert.ipynb\t  text_summarization.ipynb\t   text_summarization_v3.ipynb\n",
            "'mert (1).ipynb'   mutant.ipynb   text_summarization_model.keras   Untitled0.ipynb\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Current directory\n",
        "print(\"You are currently in\", os.getcwd(), \"directory\")\n",
        "\n",
        "# Path to dataset\n",
        "!ls /content/drive/My\\ Drive/Colab\\ Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "H3xkcPTyD0A9",
        "outputId": "8235fec2-7c75-49c6-d847-a0c8ded2b038"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  WASHINGTON (Reuters) - President Donald Trump ...   \n",
              "1  MOSCOW (Reuters) - Russian property developer ...   \n",
              "2  WASHINGTON (Reuters) - The U.S. intelligence c...   \n",
              "\n",
              "                                          prediction prediction_agent  \\\n",
              "0  [{'score': 1.0, 'text': 'Trump ends 'Dreamer' ...          Argilla   \n",
              "1  [{'score': 1.0, 'text': 'Russian tycoon, fresh...          Argilla   \n",
              "2  [{'score': 1.0, 'text': 'U.S. not started asse...          Argilla   \n",
              "\n",
              "  annotation annotation_agent                                    id metadata  \\\n",
              "0       None             None  04de325a-1fbf-41a9-977b-ec7892ef86f0     None   \n",
              "1       None             None  97c7f5e7-ae32-44af-ad0c-e6b17ce31e54     None   \n",
              "2       None             None  90894659-b843-4817-9df8-bb34d6219cdf     None   \n",
              "\n",
              "    status event_timestamp                metrics  \n",
              "0  Default      2017-09-05  {'text_length': 6904}  \n",
              "1  Default      2017-11-08  {'text_length': 1527}  \n",
              "2  Default      2017-05-23   {'text_length': 677}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0ba9dde0-9e1e-468a-a463-186fe2d6d7cd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>prediction</th>\n",
              "      <th>prediction_agent</th>\n",
              "      <th>annotation</th>\n",
              "      <th>annotation_agent</th>\n",
              "      <th>id</th>\n",
              "      <th>metadata</th>\n",
              "      <th>status</th>\n",
              "      <th>event_timestamp</th>\n",
              "      <th>metrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WASHINGTON (Reuters) - President Donald Trump ...</td>\n",
              "      <td>[{'score': 1.0, 'text': 'Trump ends 'Dreamer' ...</td>\n",
              "      <td>Argilla</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>04de325a-1fbf-41a9-977b-ec7892ef86f0</td>\n",
              "      <td>None</td>\n",
              "      <td>Default</td>\n",
              "      <td>2017-09-05</td>\n",
              "      <td>{'text_length': 6904}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MOSCOW (Reuters) - Russian property developer ...</td>\n",
              "      <td>[{'score': 1.0, 'text': 'Russian tycoon, fresh...</td>\n",
              "      <td>Argilla</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>97c7f5e7-ae32-44af-ad0c-e6b17ce31e54</td>\n",
              "      <td>None</td>\n",
              "      <td>Default</td>\n",
              "      <td>2017-11-08</td>\n",
              "      <td>{'text_length': 1527}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WASHINGTON (Reuters) - The U.S. intelligence c...</td>\n",
              "      <td>[{'score': 1.0, 'text': 'U.S. not started asse...</td>\n",
              "      <td>Argilla</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>90894659-b843-4817-9df8-bb34d6219cdf</td>\n",
              "      <td>None</td>\n",
              "      <td>Default</td>\n",
              "      <td>2017-05-23</td>\n",
              "      <td>{'text_length': 677}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ba9dde0-9e1e-468a-a463-186fe2d6d7cd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0ba9dde0-9e1e-468a-a463-186fe2d6d7cd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0ba9dde0-9e1e-468a-a463-186fe2d6d7cd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0d24a7c0-398e-4e4c-86c8-4575748a510e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d24a7c0-398e-4e4c-86c8-4575748a510e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0d24a7c0-398e-4e4c-86c8-4575748a510e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Read the Parquet file\n",
        "import os\n",
        "import pandas as pd\n",
        "df = pd.read_parquet('ds1.parquet')\n",
        "\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGPLju1XEGUI"
      },
      "source": [
        "---\n",
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tX9F4HxSEHNh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLrNZoOeEL5r"
      },
      "source": [
        "Extract the 'text' from the 'prediction' column. Handle special tokens in target text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text\n",
        "def extract_text(x):\n",
        "    if isinstance(x, np.ndarray) and len(x) > 0 and 'text' in x[0]:\n",
        "        return x[0]['text']\n",
        "    return ''\n",
        "\n",
        "# Extract texts for summaries\n",
        "df['text_prediction'] = df['prediction'].apply(extract_text)\n",
        "\n",
        "# Handle special tokens\n",
        "df['text_prediction'] = df['text_prediction'].apply(lambda x: '<sos> ' + x + ' <eos>')"
      ],
      "metadata": {
        "id": "H0A7jREutF3l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even if `Tokenizer` will handle, to make sure, apply basic text cleaning to input text"
      ],
      "metadata": {
        "id": "ph9K9jx-uS2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(txt):\n",
        "    txt = str(txt).lower()                      # Convert to lowercase\n",
        "    txt = re.sub(r'[^a-z0-9\\s.,!?]', '', txt)   # Remove special characters except basic punctuation\n",
        "    txt = re.sub(r'\\s+', ' ', txt).strip()      # Replace multiple spaces with single space\n",
        "    return txt\n",
        "\n",
        "# Clean input text\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Clean target text\n",
        "df['text_prediction'] = df['text_prediction'].apply(clean_text)"
      ],
      "metadata": {
        "id": "I9LghXnGtyoj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dw0ekoFEPfo"
      },
      "source": [
        "Tokenize the text data and convert it to sequences using TensorFlow/Keras Tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t_tFmSH4ERxC"
      },
      "outputs": [],
      "source": [
        "# Define max vocabulary size\n",
        "max_vocab_size = 20000\n",
        "\n",
        "# Initialize Tokenizer, handle out-of-vocabulary words\n",
        "tokenizer = Tokenizer(num_words=max_vocab_size, oov_token='<UNK>')\n",
        "\n",
        "# Convert texts to list\n",
        "all_texts = df['text'].tolist() + df['text_prediction'].tolist()\n",
        "\n",
        "# Fit the tokenizer\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "# Convert a given text into a sequence of integer IDs\n",
        "def text_to_ids(txt):\n",
        "    return tokenizer.texts_to_sequences([txt])[0]\n",
        "\n",
        "# Apply text_to_ids function\n",
        "df['enc_ids'] = df['text'].apply(text_to_ids)\n",
        "df['dec_ids'] = df['text_prediction'].apply(text_to_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5bPw6pPEgKz"
      },
      "source": [
        "Pad and truncate sequences to ensure uniform input length."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define max input and target lengths\n",
        "max_input_length = 1000\n",
        "max_summary_length = 50\n",
        "\n",
        "# If text length < maximum text length, apply post padding. Else, trunctate text\n",
        "enc_in = pad_sequences(df['enc_ids'], maxlen=max_input_length, padding='post', truncating='post')\n",
        "dec_in_out = pad_sequences(df['dec_ids'], maxlen=max_summary_length, padding='post', truncating='post')\n",
        "\n",
        "# Identify rows with non-empty sequences by summing each row\n",
        "valid_idx = np.where(enc_in.sum(axis=1) != 0)[0]\n",
        "\n",
        "# Retain only non-empty sequences for model input and output\n",
        "enc_in = enc_in[valid_idx]\n",
        "dec_in_out= dec_in_out[valid_idx]"
      ],
      "metadata": {
        "id": "iEc2oxhNzKal"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9staZKBeFQV0"
      },
      "source": [
        "---\n",
        "## Model Development"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EMUvNkSEFYKn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, Model\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Z3nQLUHhvw"
      },
      "source": [
        "Build a Seq2Seq model in TensorFlow with the following components:\n",
        "- Encoder (RNN/LSTM/GRU)\n",
        "- Decoder with attention mechanism.\n",
        "- Attention layer to enhance summary quality."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This custom layer implements coverage-based Bahdanau attention to mitigate repetitive attention issues by incorporating a coverage mechanism."
      ],
      "metadata": {
        "id": "V3K5H1kV3ve8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oIH4eY1uGM3o"
      },
      "outputs": [],
      "source": [
        "class CoverageAttention(layers.Layer):\n",
        "    \"\"\"\n",
        "    Implements coverage-based Bahdanau attention to address the issue of repetitive attention.\n",
        "    This layer enhances the attention mechanism by incorporating past attention distribution (coverage).\n",
        "    \"\"\"\n",
        "    def __init__(self, units):\n",
        "        \"\"\"\n",
        "        Initializes the CoverageAttention layer.\n",
        "\n",
        "        Args:\n",
        "            units (int): Number of hidden units in the attention mechanism.\n",
        "        \"\"\"\n",
        "        super(CoverageAttention, self).__init__()\n",
        "        self.W1 = layers.Dense(units)  # Weight for encoder outputs\n",
        "        self.W2 = layers.Dense(units)  # Weight for decoder hidden state\n",
        "        self.V = layers.Dense(1)        # Final dense layer to produce attention scores\n",
        "        self.coverage_dense = layers.Dense(units, activation='relu')  # Coverage dense layer\n",
        "\n",
        "    def call(self, dec_h, enc_outputs, coverage):\n",
        "        \"\"\"\n",
        "        Compute the context vector and attention weights.\n",
        "\n",
        "        Args:\n",
        "            dec_h (Tensor): Decoder hidden state (batch_size, dec_units).\n",
        "            enc_outputs (Tensor): Encoder outputs (batch_size, max_enc_len, enc_units).\n",
        "            coverage (Tensor): Accumulated attention scores (batch_size, max_enc_len).\n",
        "\n",
        "        Returns:\n",
        "            context_vector (Tensor): Weighted sum of encoder outputs (batch_size, enc_units).\n",
        "            attn_weights (Tensor): Attention weights (batch_size, max_enc_len, 1).\n",
        "            coverage (Tensor): Updated coverage vector (batch_size, max_enc_len).\n",
        "        \"\"\"\n",
        "        # Expand dimensions to match encoder outputs\n",
        "        dec_h_expanded = tf.expand_dims(dec_h, 1)  # Shape: (batch_size, 1, dec_units)\n",
        "        coverage_expanded = tf.expand_dims(coverage, -1)  # Shape: (batch_size, max_enc_len, 1)\n",
        "\n",
        "        # Compute coverage feature\n",
        "        coverage_feat = self.coverage_dense(coverage_expanded)  # Shape: (batch_size, max_enc_len, units)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(enc_outputs) + self.W2(dec_h_expanded) + coverage_feat\n",
        "        ))  # Shape: (batch_size, max_enc_len, 1)\n",
        "\n",
        "        # Compute attention weights\n",
        "        attn_weights = tf.nn.softmax(score, axis=1)  # Shape: (batch_size, max_enc_len, 1)\n",
        "\n",
        "        # Compute context vector as the weighted sum of encoder outputs\n",
        "        context_vector = attn_weights * enc_outputs  # Shape: (batch_size, max_enc_len, enc_units)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)  # Shape: (batch_size, enc_units)\n",
        "\n",
        "        # Update coverage vector by adding current attention weights\n",
        "        coverage += tf.squeeze(attn_weights, axis=-1)  # Shape: (batch_size, max_enc_len)\n",
        "\n",
        "        return context_vector, attn_weights, coverage\n",
        "\n",
        "# Function to combine the vocabulary distribution and attention distribution using the pointer-generator mechanism\n",
        "def calc_final_dist(vocab_dist, attn_dist, p_gen, enc_inputs, vocab_size):\n",
        "    \"\"\"\n",
        "    Calculate the final probability distribution by combining vocab distribution\n",
        "    and attention distribution based on the pointer-generator network mechanism.\n",
        "\n",
        "    Args:\n",
        "        vocab_dist (Tensor): Vocabulary distribution (batch_size, vocab_size).\n",
        "        attn_dist (Tensor): Attention distribution (batch_size, max_enc_len).\n",
        "        p_gen (Tensor): Generation probability scalar (batch_size, 1).\n",
        "        enc_inputs (Tensor): Encoder input IDs (batch_size, max_enc_len).\n",
        "        vocab_size (int): Total vocabulary size.\n",
        "\n",
        "    Returns:\n",
        "        final_dist (Tensor): Final combined distribution (batch_size, vocab_size).\n",
        "    \"\"\"\n",
        "    # Calculate the weighted distributions\n",
        "    vocab_part = p_gen * vocab_dist          # Probability of generating from vocab\n",
        "    copy_part = (1.0 - p_gen) * attn_dist    # Probability of copying from input\n",
        "\n",
        "    # Scatter to combine attention and vocabulary distributions\n",
        "    def scatter_one(args):\n",
        "        v_b, c_b, e_b = args\n",
        "        indices = tf.expand_dims(e_b, axis=-1)  # Shape: (max_enc_len, 1)\n",
        "        return tf.tensor_scatter_nd_add(v_b, indices, c_b)  # Shape: (vocab_size,)\n",
        "\n",
        "    final_dist = tf.map_fn(\n",
        "        scatter_one,\n",
        "        (vocab_part, copy_part, enc_inputs),\n",
        "        fn_output_signature=tf.float32  # Final output shape: (batch_size, vocab_size)\n",
        "    )\n",
        "    return final_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model combines sequence-to-sequence architecture with attention and coverage mechanisms to generate summaries."
      ],
      "metadata": {
        "id": "YoJKkTsi5Ul0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PointerGenCoverage(Model):\n",
        "    \"\"\"\n",
        "    Pointer-Generator Network with Coverage Mechanism.\n",
        "    This model combines the power of sequence-to-sequence models with attention,\n",
        "    and introduces coverage to reduce repetition in generated text.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim, enc_units, dec_units, max_enc_len):\n",
        "        \"\"\"\n",
        "        Initializes the PointerGenCoverage model.\n",
        "\n",
        "        Args:\n",
        "            vocab_size (int): Size of the vocabulary.\n",
        "            embed_dim (int): Dimension of the embedding vectors.\n",
        "            enc_units (int): Number of units in the encoder LSTM.\n",
        "            dec_units (int): Number of units in the decoder LSTM.\n",
        "            max_enc_len (int): Maximum length of encoder input sequences.\n",
        "        \"\"\"\n",
        "        super(PointerGenCoverage, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.enc_units = enc_units\n",
        "        self.dec_units = dec_units\n",
        "        self.max_enc_len = max_enc_len\n",
        "\n",
        "        # Embedding layer to encode input tokens\n",
        "        self.embedding = Embedding(\n",
        "            input_dim=vocab_size,\n",
        "            output_dim=embed_dim,\n",
        "            mask_zero=False,\n",
        "            name=\"embedding\"\n",
        "        )\n",
        "\n",
        "        # Encoder LSTM to process input sequences\n",
        "        self.encoder_lstm = LSTM(\n",
        "            enc_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            name=\"encoder_lstm\"\n",
        "        )\n",
        "\n",
        "        # Decoder LSTM for generating target sequences\n",
        "        self.decoder_lstm = LSTM(\n",
        "            dec_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            name=\"decoder_lstm\"\n",
        "        )\n",
        "\n",
        "        # Attention layer with coverage\n",
        "        self.attention = CoverageAttention(dec_units)\n",
        "\n",
        "        # Dense layer for output vocabulary distribution\n",
        "        self.vocab_out = Dense(vocab_size, activation='softmax', name=\"vocab_out\")\n",
        "\n",
        "        # Pointer network gate to control copy/generate mechanism\n",
        "        self.pointer_gate = Dense(1, activation='sigmoid', name=\"pointer_gate\")\n",
        "\n",
        "    def call_encoder(self, enc_inputs):\n",
        "        \"\"\"\n",
        "        Encodes the input sequence into hidden states.\n",
        "\n",
        "        Args:\n",
        "            enc_inputs (Tensor): Encoder input tensor (batch_size, max_enc_len).\n",
        "\n",
        "        Returns:\n",
        "            enc_outputs (Tensor): Encoder outputs (batch_size, max_enc_len, enc_units).\n",
        "            enc_h (Tensor): Final hidden state of the encoder (batch_size, enc_units).\n",
        "            enc_c (Tensor): Final cell state of the encoder (batch_size, enc_units).\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(enc_inputs)  # Shape: (batch_size, max_enc_len, embed_dim)\n",
        "        enc_outputs, enc_h, enc_c = self.encoder_lstm(embedded)\n",
        "        return enc_outputs, enc_h, enc_c\n",
        "\n",
        "    def decode_step(self, dec_input, dec_h, dec_c, coverage, enc_outputs, enc_inputs):\n",
        "        \"\"\"\n",
        "        Perform a single decoding step.\n",
        "\n",
        "        Args:\n",
        "            dec_input (Tensor): Current decoder input (batch_size,).\n",
        "            dec_h (Tensor): Decoder hidden state (batch_size, dec_units).\n",
        "            dec_c (Tensor): Decoder cell state (batch_size, dec_units).\n",
        "            coverage (Tensor): Coverage vector (batch_size, max_enc_len).\n",
        "            enc_outputs (Tensor): Encoder outputs (batch_size, max_enc_len, enc_units).\n",
        "            enc_inputs (Tensor): Encoder input IDs (batch_size, max_enc_len).\n",
        "\n",
        "        Returns:\n",
        "            final_dist (Tensor): Final vocabulary distribution (batch_size, vocab_size).\n",
        "            new_h (Tensor): Updated decoder hidden state (batch_size, dec_units).\n",
        "            new_c (Tensor): Updated decoder cell state (batch_size, dec_units).\n",
        "            new_cov (Tensor): Updated coverage vector (batch_size, max_enc_len).\n",
        "        \"\"\"\n",
        "        embedded = self.embedding(dec_input)  # Shape: (batch_size, embed_dim)\n",
        "        embedded = tf.expand_dims(embedded, axis=1)  # Shape: (batch_size, 1, embed_dim)\n",
        "\n",
        "        # Pass through decoder LSTM\n",
        "        dec_outputs, new_h, new_c = self.decoder_lstm(embedded, initial_state=[dec_h, dec_c])\n",
        "        dec_outputs = tf.squeeze(dec_outputs, axis=1)  # Shape: (batch_size, dec_units)\n",
        "\n",
        "        # Calculate attention with coverage\n",
        "        context_vector, attn_weights, new_cov = self.attention(new_h, enc_outputs, coverage)\n",
        "\n",
        "        # Concatenate decoder output and context vector\n",
        "        concat_vector = tf.concat([dec_outputs, context_vector], axis=-1)  # Shape: (batch_size, dec_units + enc_units)\n",
        "\n",
        "        # Compute vocabulary distribution\n",
        "        vocab_distribution = self.vocab_out(concat_vector)  # Shape: (batch_size, vocab_size)\n",
        "\n",
        "        # Compute pointer gate value\n",
        "        p_gen = self.pointer_gate(concat_vector)  # Shape: (batch_size, 1)\n",
        "\n",
        "        # Squeeze attention weights for final distribution calculation\n",
        "        attn_weights_squeezed = tf.squeeze(attn_weights, axis=-1)  # Shape: (batch_size, max_enc_len)\n",
        "\n",
        "        # Calculate final distribution by combining vocabulary and attention distributions\n",
        "        final_distribution = calc_final_dist(\n",
        "            vocab_distribution,\n",
        "            attn_weights_squeezed,\n",
        "            p_gen,\n",
        "            enc_inputs,\n",
        "            self.vocab_size\n",
        "        )  # Shape: (batch_size, vocab_size)\n",
        "\n",
        "        return final_distribution, new_h, new_c, new_cov\n",
        "\n",
        "    def call(self, enc_inputs, dec_inputs):\n",
        "        \"\"\"\n",
        "        Forward pass for the Pointer-Generator model.\n",
        "\n",
        "        Args:\n",
        "            enc_inputs (Tensor): Encoder input tensor (batch_size, max_enc_len).\n",
        "            dec_inputs (Tensor): Decoder input tensor (batch_size, max_dec_len).\n",
        "\n",
        "        Returns:\n",
        "            final_dists (Tensor): Final distributions for all decoding steps (batch_size, max_dec_len, vocab_size).\n",
        "        \"\"\"\n",
        "        # Encode the input sequences\n",
        "        enc_outputs, enc_h, enc_c = self.call_encoder(enc_inputs)\n",
        "\n",
        "        # Initialize decoder states with encoder's final states\n",
        "        dec_h, dec_c = enc_h, enc_c\n",
        "\n",
        "        # Initialize coverage vector to zeros\n",
        "        batch_size = tf.shape(enc_inputs)[0]\n",
        "        coverage = tf.zeros((batch_size, self.max_enc_len))\n",
        "\n",
        "        # Initialize list to collect final distributions\n",
        "        final_dists = []\n",
        "\n",
        "        # Iterate over each time step in the decoder input\n",
        "        for t in range(dec_inputs.shape[1]):\n",
        "            # Get the decoder input for the current time step\n",
        "            dec_input_t = dec_inputs[:, t]\n",
        "\n",
        "            # Perform a decoding step\n",
        "            final_dist, dec_h, dec_c, coverage = self.decode_step(\n",
        "                dec_input_t, dec_h, dec_c, coverage, enc_outputs, enc_inputs\n",
        "            )\n",
        "\n",
        "            # Append the final distribution to the list\n",
        "            final_dists.append(final_dist)\n",
        "\n",
        "        # Stack the final distributions along the time axis\n",
        "        final_dists = tf.stack(final_dists, axis=1)  # Shape: (batch_size, max_dec_len, vocab_size)\n",
        "\n",
        "        return final_dists"
      ],
      "metadata": {
        "id": "sk_c-Qrk1bZK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6cMbFs1LfeB"
      },
      "source": [
        "---\n",
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3gdrtRsHq1o"
      },
      "source": [
        "Since we have the model, we will split our data (%80 train / %10 validation / %10 test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "O0VfAk93Hvpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3aa546-2325-490b-ead0-5ee32b03f006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (16332, 1000), (16332, 50)\n",
            "Validation set: (2042, 1000), (2042, 50)\n",
            "Test set: (2042, 1000), (2042, 50)\n"
          ]
        }
      ],
      "source": [
        "# First split: 80% training and 20% temporary (to be further split)\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(\n",
        "    enc_in, dec_in_out, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Second split: Split the 20% temporary data into 10% validation and 10% test\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(\n",
        "    X_temp, Y_temp, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "# Verify the shapes\n",
        "print(f\"Training set: {X_train.shape}, {Y_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}, {Y_val.shape}\")\n",
        "print(f\"Test set: {X_test.shape}, {Y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZIeYnkdKfgQ"
      },
      "source": [
        "We do step-by-step decoding to compute the loss for each time step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tZeGCPx2Km3-"
      },
      "outputs": [],
      "source": [
        "# Use sparse categorical cross entropy as loss function\n",
        "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=False, reduction='none'\n",
        ")\n",
        "\n",
        "def pgn_coverage_loss(final_dist, target_token):\n",
        "    \"\"\"\n",
        "    Computes the pointer-generator coverage loss.\n",
        "\n",
        "    Args:\n",
        "        final_dist (Tensor): Final distribution over the vocabulary (batch_size, vocab_size).\n",
        "        target_token (Tensor): Ground-truth token IDs (batch_size,).\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Per-example loss (batch_size,).\n",
        "    \"\"\"\n",
        "    # Compute the loss for each example in the batch\n",
        "    loss = loss_obj(target_token, final_dist)  # Shape: (batch_size,)\n",
        "    return loss\n",
        "\n",
        "def pgn_accuracy(final_dist, target_token):\n",
        "    \"\"\"\n",
        "    Computes the token-level accuracy.\n",
        "\n",
        "    Args:\n",
        "        final_dist (Tensor): Final distribution over the vocabulary (batch_size, vocab_size).\n",
        "        target_token (Tensor): Ground-truth token IDs (batch_size,).\n",
        "\n",
        "    Returns:\n",
        "        Tensor: Accuracy for the batch (scalar).\n",
        "    \"\"\"\n",
        "    # Predicted token is the one with the highest probability\n",
        "    pred_token = tf.argmax(final_dist, axis=-1, output_type=tf.int32)  # Shape: (batch_size,)\n",
        "\n",
        "    # Compare with target tokens\n",
        "    correct = tf.cast(tf.equal(pred_token, target_token), tf.float32)  # Shape: (batch_size,)\n",
        "\n",
        "    # Compute average accuracy\n",
        "    accuracy = tf.reduce_mean(correct)  # Scalar\n",
        "    return accuracy\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, optimizer, enc_inp, dec_inp, dec_out):\n",
        "    \"\"\"\n",
        "    Performs a single training step.\n",
        "\n",
        "    Args:\n",
        "        model (PointerGenCoverage): The model to train.\n",
        "        optimizer (tf.keras.optimizers.Optimizer): Optimizer for training.\n",
        "        enc_inp (Tensor): Encoder input tensor (batch_size, max_enc_len).\n",
        "        dec_inp (Tensor): Decoder input tensor (batch_size, max_dec_len-1).\n",
        "        dec_out (Tensor): Decoder output tensor (batch_size, max_dec_len-1).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Tensor, Tensor]: Batch loss and batch accuracy.\n",
        "    \"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Encode the input sequences\n",
        "        enc_outputs, enc_h, enc_c = model.call_encoder(enc_inp)\n",
        "\n",
        "        # Initialize decoder states with encoder's final states\n",
        "        dec_h, dec_c = enc_h, enc_c\n",
        "\n",
        "        # Initialize coverage vector to zeros\n",
        "        coverage = tf.zeros((tf.shape(enc_inp)[0], model.max_enc_len))\n",
        "\n",
        "        # Initialize loss and accuracy\n",
        "        total_loss = tf.constant(0.0)\n",
        "        total_accuracy = tf.constant(0.0)\n",
        "\n",
        "        # Iterate over each time step in the decoder input\n",
        "        for t in range(dec_inp.shape[1]):\n",
        "            # Get the decoder input and target for the current time step\n",
        "            current_token_in = dec_inp[:, t]\n",
        "            current_token_out = dec_out[:, t]\n",
        "\n",
        "            # Perform a decoding step\n",
        "            final_dist, dec_h, dec_c, coverage = model.decode_step(\n",
        "                current_token_in, dec_h, dec_c, coverage, enc_outputs, enc_inp\n",
        "            )\n",
        "\n",
        "            # Compute loss and accuracy\n",
        "            loss = pgn_coverage_loss(final_dist, current_token_out)  # Shape: (batch_size,)\n",
        "            acc = pgn_accuracy(final_dist, current_token_out)        # Scalar\n",
        "\n",
        "            # Accumulate loss and accuracy\n",
        "            total_loss += tf.reduce_mean(loss)\n",
        "            total_accuracy += acc\n",
        "\n",
        "        # Average loss and accuracy over all time steps\n",
        "        batch_loss = total_loss / tf.cast(dec_inp.shape[1], tf.float32)\n",
        "        batch_accuracy = total_accuracy / tf.cast(dec_inp.shape[1], tf.float32)\n",
        "\n",
        "    # Compute gradients and apply them\n",
        "    variables = model.trainable_variables\n",
        "    grads = tape.gradient(batch_loss, variables)\n",
        "    optimizer.apply_gradients(zip(grads, variables))\n",
        "\n",
        "    return batch_loss, batch_accuracy\n",
        "\n",
        "def train_epochs(model, optimizer, X_train, Y_train, X_val, Y_val, epochs=5, batch_size=16):\n",
        "    \"\"\"\n",
        "    Trains the model for a specified number of epochs.\n",
        "\n",
        "    Args:\n",
        "        model (PointerGenCoverage): The model to train.\n",
        "        optimizer (tf.keras.optimizers.Optimizer): Optimizer for training.\n",
        "        X_train (ndarray): Training encoder inputs (num_train, max_enc_len).\n",
        "        Y_train (ndarray): Training decoder outputs (num_train, max_dec_len).\n",
        "        X_val (ndarray): Validation encoder inputs (num_val, max_enc_len).\n",
        "        Y_val (ndarray): Validation decoder outputs (num_val, max_dec_len).\n",
        "        epochs (int): Number of epochs to train.\n",
        "        batch_size (int): Size of each training batch.\n",
        "    \"\"\"\n",
        "    # Prepare decoder inputs and outputs by shifting\n",
        "    dec_in_train = Y_train[:, :-1]  # Decoder input (start with <sos>)\n",
        "    dec_out_train = Y_train[:, 1:]  # Decoder output (end with <eos>)\n",
        "    dec_in_val   = Y_val[:, :-1]\n",
        "    dec_out_val  = Y_val[:, 1:]\n",
        "\n",
        "    steps_per_epoch = len(X_train) // batch_size\n",
        "    val_steps       = len(X_val) // batch_size\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        print(f\"=== Epoch {ep}/{epochs} ===\")\n",
        "        total_train_loss = 0.0\n",
        "        total_train_accuracy = 0.0\n",
        "\n",
        "        # Shuffle the training data\n",
        "        idxs = np.random.permutation(len(X_train))\n",
        "        X_train_shuff = X_train[idxs]\n",
        "        di_train_shuff = dec_in_train[idxs]\n",
        "        do_train_shuff = dec_out_train[idxs]\n",
        "\n",
        "        for step in range(steps_per_epoch):\n",
        "            start = step * batch_size\n",
        "            end = (step + 1) * batch_size\n",
        "            enc_inp_batch = X_train_shuff[start:end]\n",
        "            dec_inp_batch = di_train_shuff[start:end]\n",
        "            dec_out_batch = do_train_shuff[start:end]\n",
        "\n",
        "            # Convert to tensors\n",
        "            enc_inp_batch = tf.convert_to_tensor(enc_inp_batch, dtype=tf.int32)\n",
        "            dec_inp_batch = tf.convert_to_tensor(dec_inp_batch, dtype=tf.int32)\n",
        "            dec_out_batch = tf.convert_to_tensor(dec_out_batch, dtype=tf.int32)\n",
        "\n",
        "            # Perform a training step\n",
        "            batch_loss, batch_accuracy = train_step(model, optimizer, enc_inp_batch, dec_inp_batch, dec_out_batch)\n",
        "\n",
        "            # Accumulate loss and accuracy\n",
        "            total_train_loss += batch_loss.numpy()\n",
        "            total_train_accuracy += batch_accuracy.numpy()\n",
        "\n",
        "            if (step + 1) % 10 == 0:\n",
        "                print(f\"  step {step + 1}/{steps_per_epoch}, loss={batch_loss.numpy():.4f}, accuracy={batch_accuracy.numpy():.4f}\")\n",
        "\n",
        "        # Compute average training loss and accuracy\n",
        "        avg_train_loss = total_train_loss / steps_per_epoch\n",
        "        avg_train_accuracy = total_train_accuracy / steps_per_epoch\n",
        "        print(f\"  >> Epoch {ep} train loss: {avg_train_loss:.4f}, train accuracy: {avg_train_accuracy:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        total_val_loss = 0.0\n",
        "        total_val_accuracy = 0.0\n",
        "        for step in range(val_steps):\n",
        "            start = step * batch_size\n",
        "            end = (step + 1) * batch_size\n",
        "            enc_inp_batch = X_val[start:end]\n",
        "            dec_inp_batch = dec_in_val[start:end]\n",
        "            dec_out_batch = dec_out_val[start:end]\n",
        "\n",
        "            # Convert to tensors\n",
        "            enc_inp_batch = tf.convert_to_tensor(enc_inp_batch, dtype=tf.int32)\n",
        "            dec_inp_batch = tf.convert_to_tensor(dec_inp_batch, dtype=tf.int32)\n",
        "            dec_out_batch = tf.convert_to_tensor(dec_out_batch, dtype=tf.int32)\n",
        "\n",
        "            # Perform a forward pass without gradient computation\n",
        "            enc_outputs, enc_h, enc_c = model.call_encoder(enc_inp_batch)\n",
        "            coverage = tf.zeros((batch_size, model.max_enc_len))\n",
        "            dec_h, dec_c = enc_h, enc_c\n",
        "            batch_val_loss = 0.0\n",
        "            batch_val_accuracy = 0.0\n",
        "\n",
        "            for t in range(dec_inp_batch.shape[1]):\n",
        "                fin_dist, dec_h, dec_c, coverage = model.decode_step(\n",
        "                    dec_inp_batch[:, t], dec_h, dec_c, coverage, enc_outputs, enc_inp_batch\n",
        "                )\n",
        "                loss = pgn_coverage_loss(fin_dist, dec_out_batch[:, t])\n",
        "                acc = pgn_accuracy(fin_dist, dec_out_batch[:, t])\n",
        "\n",
        "                batch_val_loss += tf.reduce_mean(loss).numpy()\n",
        "                batch_val_accuracy += acc.numpy()\n",
        "\n",
        "            # Average over time steps\n",
        "            batch_val_loss /= dec_inp_batch.shape[1]\n",
        "            batch_val_accuracy /= dec_inp_batch.shape[1]\n",
        "            total_val_loss += batch_val_loss\n",
        "            total_val_accuracy += batch_val_accuracy\n",
        "\n",
        "        # Compute average validation loss and accuracy\n",
        "        avg_val_loss = total_val_loss / val_steps if val_steps > 0 else 0.0\n",
        "        avg_val_accuracy = total_val_accuracy / val_steps if val_steps > 0 else 0.0\n",
        "        print(f\"  >> Epoch {ep} val loss: {avg_val_loss:.4f}, val accuracy: {avg_val_accuracy:.4f}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and summarize the model"
      ],
      "metadata": {
        "id": "1ThDWTaFEnWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_and_summarize_model(vocab_size, embed_dim, enc_units, dec_units, max_enc_len, max_dec_len):\n",
        "    \"\"\"\n",
        "    Builds the Pointer-Generator Coverage model and prints its summary.\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int): Size of the vocabulary.\n",
        "        embed_dim (int): Dimension of the embedding vectors.\n",
        "        enc_units (int): Number of units in the encoder LSTM.\n",
        "        dec_units (int): Number of units in the decoder LSTM.\n",
        "        max_enc_len (int): Maximum length of encoder input sequences.\n",
        "        max_dec_len (int): Maximum length of decoder input sequences.\n",
        "\n",
        "    Returns:\n",
        "        model (PointerGenCoverage): Instantiated Pointer-Generator Coverage model.\n",
        "    \"\"\"\n",
        "    # Instantiate the model\n",
        "    model = PointerGenCoverage(\n",
        "        vocab_size=vocab_size,\n",
        "        embed_dim=embed_dim,\n",
        "        enc_units=enc_units,\n",
        "        dec_units=dec_units,\n",
        "        max_enc_len=max_enc_len\n",
        "    )\n",
        "\n",
        "    # Define inputs with integer dtype\n",
        "    enc_inputs = tf.keras.Input(shape=(max_enc_len,), dtype='int32', name='enc_inputs')\n",
        "    dec_inputs = tf.keras.Input(shape=(max_dec_len,), dtype='int32', name='dec_inputs')\n",
        "\n",
        "    # Get the model outputs\n",
        "    outputs = model(enc_inputs, dec_inputs)\n",
        "\n",
        "    # Create the Keras model\n",
        "    keras_model = Model(inputs=[enc_inputs, dec_inputs], outputs=outputs, name=\"PointerGenCoverage\")\n",
        "\n",
        "    # Print the model summary\n",
        "    keras_model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "jQmWGnCHEphI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1fd2nm8IVer"
      },
      "source": [
        "\n",
        "Finally, we can train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1ppI9m0nIYRO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1f7691e-d49d-473e-97dc-51d2124bb36b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"PointerGenCoverage\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"PointerGenCoverage\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ enc_inputs (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dec_inputs (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pointer_gen_coverage      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m20000\u001b[0m)      │     \u001b[38;5;34m13,741,346\u001b[0m │ enc_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mPointerGenCoverage\u001b[0m)      │                        │                │ dec_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ enc_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dec_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ pointer_gen_coverage      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">13,741,346</span> │ enc_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PointerGenCoverage</span>)      │                        │                │ dec_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,741,346\u001b[0m (52.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,741,346</span> (52.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,741,346\u001b[0m (52.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,741,346</span> (52.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training with Pointer-Generator + Coverage (custom loop) ...\n",
            "\n",
            "=== Epoch 1/5 ===\n",
            "  step 10/510, loss=2.0172, accuracy=0.7730\n",
            "  step 20/510, loss=2.1097, accuracy=0.7290\n",
            "  step 30/510, loss=2.0177, accuracy=0.7073\n",
            "  step 40/510, loss=1.1709, accuracy=0.7838\n",
            "  step 50/510, loss=1.2844, accuracy=0.7864\n",
            "  step 60/510, loss=1.1564, accuracy=0.7927\n",
            "  step 70/510, loss=1.1718, accuracy=0.7972\n",
            "  step 80/510, loss=1.1759, accuracy=0.7966\n",
            "  step 90/510, loss=1.1689, accuracy=0.7997\n",
            "  step 100/510, loss=1.2015, accuracy=0.7966\n",
            "  step 110/510, loss=1.1561, accuracy=0.8042\n",
            "  step 120/510, loss=1.2022, accuracy=0.8042\n",
            "  step 130/510, loss=1.0816, accuracy=0.8157\n",
            "  step 140/510, loss=1.0978, accuracy=0.8112\n",
            "  step 150/510, loss=1.1183, accuracy=0.8131\n",
            "  step 160/510, loss=1.1392, accuracy=0.8099\n",
            "  step 170/510, loss=1.1190, accuracy=0.8131\n",
            "  step 180/510, loss=1.0875, accuracy=0.8080\n",
            "  step 190/510, loss=1.1424, accuracy=0.8080\n",
            "  step 200/510, loss=1.1015, accuracy=0.8087\n",
            "  step 210/510, loss=1.0424, accuracy=0.8284\n",
            "  step 220/510, loss=1.0688, accuracy=0.8112\n",
            "  step 230/510, loss=1.0129, accuracy=0.8284\n",
            "  step 240/510, loss=1.0685, accuracy=0.8157\n",
            "  step 250/510, loss=1.0941, accuracy=0.8131\n",
            "  step 260/510, loss=1.0214, accuracy=0.8157\n",
            "  step 270/510, loss=1.0253, accuracy=0.8202\n",
            "  step 280/510, loss=1.0911, accuracy=0.8112\n",
            "  step 290/510, loss=1.0764, accuracy=0.8157\n",
            "  step 300/510, loss=1.0748, accuracy=0.8182\n",
            "  step 310/510, loss=1.0244, accuracy=0.8240\n",
            "  step 320/510, loss=1.0406, accuracy=0.8176\n",
            "  step 330/510, loss=1.0257, accuracy=0.8157\n",
            "  step 340/510, loss=1.0274, accuracy=0.8278\n",
            "  step 350/510, loss=1.0417, accuracy=0.8157\n",
            "  step 360/510, loss=0.9281, accuracy=0.8367\n",
            "  step 370/510, loss=1.0244, accuracy=0.8119\n",
            "  step 380/510, loss=1.0201, accuracy=0.8253\n",
            "  step 390/510, loss=1.1216, accuracy=0.8080\n",
            "  step 400/510, loss=1.0712, accuracy=0.8176\n",
            "  step 410/510, loss=1.0108, accuracy=0.8202\n",
            "  step 420/510, loss=0.8938, accuracy=0.8253\n",
            "  step 430/510, loss=1.0174, accuracy=0.8278\n",
            "  step 440/510, loss=1.0154, accuracy=0.8297\n",
            "  step 450/510, loss=1.0518, accuracy=0.8163\n",
            "  step 460/510, loss=0.9946, accuracy=0.8189\n",
            "  step 470/510, loss=0.9742, accuracy=0.8310\n",
            "  step 480/510, loss=1.0534, accuracy=0.8284\n",
            "  step 490/510, loss=0.9726, accuracy=0.8310\n",
            "  step 500/510, loss=1.0615, accuracy=0.8182\n",
            "  step 510/510, loss=0.9575, accuracy=0.8272\n",
            "  >> Epoch 1 train loss: 1.1309, train accuracy: 0.8098\n",
            "  >> Epoch 1 val loss: 1.0013, val accuracy: 0.8241\n",
            "\n",
            "=== Epoch 2/5 ===\n",
            "  step 10/510, loss=0.9330, accuracy=0.8310\n",
            "  step 20/510, loss=0.9674, accuracy=0.8342\n",
            "  step 30/510, loss=0.9445, accuracy=0.8265\n",
            "  step 40/510, loss=0.9788, accuracy=0.8304\n",
            "  step 50/510, loss=0.9828, accuracy=0.8329\n",
            "  step 60/510, loss=0.8713, accuracy=0.8342\n",
            "  step 70/510, loss=0.9394, accuracy=0.8380\n",
            "  step 80/510, loss=0.9783, accuracy=0.8374\n",
            "  step 90/510, loss=0.9410, accuracy=0.8259\n",
            "  step 100/510, loss=0.9273, accuracy=0.8412\n",
            "  step 110/510, loss=0.9455, accuracy=0.8335\n",
            "  step 120/510, loss=0.9155, accuracy=0.8361\n",
            "  step 130/510, loss=0.9710, accuracy=0.8246\n",
            "  step 140/510, loss=1.0389, accuracy=0.8163\n",
            "  step 150/510, loss=0.9417, accuracy=0.8272\n",
            "  step 160/510, loss=0.8815, accuracy=0.8304\n",
            "  step 170/510, loss=0.9453, accuracy=0.8240\n",
            "  step 180/510, loss=0.9516, accuracy=0.8342\n",
            "  step 190/510, loss=0.9477, accuracy=0.8304\n",
            "  step 200/510, loss=0.9444, accuracy=0.8221\n",
            "  step 210/510, loss=0.9761, accuracy=0.8214\n",
            "  step 220/510, loss=0.9963, accuracy=0.8284\n",
            "  step 230/510, loss=0.8884, accuracy=0.8457\n",
            "  step 240/510, loss=0.9724, accuracy=0.8227\n",
            "  step 250/510, loss=0.9935, accuracy=0.8227\n",
            "  step 260/510, loss=0.9312, accuracy=0.8374\n",
            "  step 270/510, loss=0.9421, accuracy=0.8329\n",
            "  step 280/510, loss=0.8542, accuracy=0.8469\n",
            "  step 290/510, loss=0.9473, accuracy=0.8323\n",
            "  step 300/510, loss=0.9185, accuracy=0.8406\n",
            "  step 310/510, loss=0.8855, accuracy=0.8406\n",
            "  step 320/510, loss=0.9141, accuracy=0.8335\n",
            "  step 330/510, loss=0.9552, accuracy=0.8316\n",
            "  step 340/510, loss=0.9141, accuracy=0.8406\n",
            "  step 350/510, loss=0.8397, accuracy=0.8469\n",
            "  step 360/510, loss=0.9643, accuracy=0.8291\n",
            "  step 370/510, loss=0.9519, accuracy=0.8393\n",
            "  step 380/510, loss=0.8701, accuracy=0.8438\n",
            "  step 390/510, loss=0.9020, accuracy=0.8380\n",
            "  step 400/510, loss=0.8816, accuracy=0.8431\n",
            "  step 410/510, loss=0.8938, accuracy=0.8476\n",
            "  step 420/510, loss=0.9221, accuracy=0.8323\n",
            "  step 430/510, loss=0.8869, accuracy=0.8335\n",
            "  step 440/510, loss=0.9870, accuracy=0.8361\n",
            "  step 450/510, loss=0.9076, accuracy=0.8508\n",
            "  step 460/510, loss=0.8984, accuracy=0.8457\n",
            "  step 470/510, loss=0.8689, accuracy=0.8463\n",
            "  step 480/510, loss=0.9854, accuracy=0.8195\n",
            "  step 490/510, loss=0.9629, accuracy=0.8374\n",
            "  step 500/510, loss=0.8611, accuracy=0.8425\n",
            "  step 510/510, loss=0.9036, accuracy=0.8520\n",
            "  >> Epoch 2 train loss: 0.9264, train accuracy: 0.8351\n",
            "  >> Epoch 2 val loss: 0.9142, val accuracy: 0.8413\n",
            "\n",
            "=== Epoch 3/5 ===\n",
            "  step 10/510, loss=0.8414, accuracy=0.8444\n",
            "  step 20/510, loss=0.8067, accuracy=0.8591\n",
            "  step 30/510, loss=0.8491, accuracy=0.8450\n",
            "  step 40/510, loss=0.7964, accuracy=0.8559\n",
            "  step 50/510, loss=0.7963, accuracy=0.8514\n",
            "  step 60/510, loss=0.7840, accuracy=0.8591\n",
            "  step 70/510, loss=0.7851, accuracy=0.8642\n",
            "  step 80/510, loss=0.8430, accuracy=0.8495\n",
            "  step 90/510, loss=0.7582, accuracy=0.8603\n",
            "  step 100/510, loss=0.8129, accuracy=0.8546\n",
            "  step 110/510, loss=0.8771, accuracy=0.8393\n",
            "  step 120/510, loss=0.7740, accuracy=0.8546\n",
            "  step 130/510, loss=0.8736, accuracy=0.8476\n",
            "  step 140/510, loss=0.8721, accuracy=0.8482\n",
            "  step 150/510, loss=0.7537, accuracy=0.8724\n",
            "  step 160/510, loss=0.7668, accuracy=0.8635\n",
            "  step 170/510, loss=0.9305, accuracy=0.8393\n",
            "  step 180/510, loss=0.8549, accuracy=0.8540\n",
            "  step 190/510, loss=0.8234, accuracy=0.8571\n",
            "  step 200/510, loss=0.7492, accuracy=0.8648\n",
            "  step 210/510, loss=0.8573, accuracy=0.8450\n",
            "  step 220/510, loss=0.7974, accuracy=0.8514\n",
            "  step 230/510, loss=0.7672, accuracy=0.8571\n",
            "  step 240/510, loss=0.8648, accuracy=0.8476\n",
            "  step 250/510, loss=0.8200, accuracy=0.8495\n",
            "  step 260/510, loss=0.8733, accuracy=0.8431\n",
            "  step 270/510, loss=0.8782, accuracy=0.8457\n",
            "  step 280/510, loss=0.7701, accuracy=0.8622\n",
            "  step 290/510, loss=0.8083, accuracy=0.8501\n",
            "  step 300/510, loss=0.7818, accuracy=0.8565\n",
            "  step 310/510, loss=0.7861, accuracy=0.8565\n",
            "  step 320/510, loss=0.7280, accuracy=0.8603\n",
            "  step 330/510, loss=0.8319, accuracy=0.8527\n",
            "  step 340/510, loss=0.8418, accuracy=0.8399\n",
            "  step 350/510, loss=0.8892, accuracy=0.8425\n",
            "  step 360/510, loss=0.8859, accuracy=0.8444\n",
            "  step 370/510, loss=0.8245, accuracy=0.8412\n",
            "  step 380/510, loss=0.7700, accuracy=0.8597\n",
            "  step 390/510, loss=0.8402, accuracy=0.8495\n",
            "  step 400/510, loss=0.9538, accuracy=0.8367\n",
            "  step 410/510, loss=0.7185, accuracy=0.8616\n",
            "  step 420/510, loss=0.8589, accuracy=0.8520\n",
            "  step 430/510, loss=0.8274, accuracy=0.8425\n",
            "  step 440/510, loss=0.8547, accuracy=0.8565\n",
            "  step 450/510, loss=0.8152, accuracy=0.8520\n",
            "  step 460/510, loss=0.8357, accuracy=0.8469\n",
            "  step 470/510, loss=0.8116, accuracy=0.8520\n",
            "  step 480/510, loss=0.8108, accuracy=0.8508\n",
            "  step 490/510, loss=0.7495, accuracy=0.8635\n",
            "  step 500/510, loss=0.8183, accuracy=0.8527\n",
            "  step 510/510, loss=0.8228, accuracy=0.8520\n",
            "  >> Epoch 3 train loss: 0.8234, train accuracy: 0.8519\n",
            "  >> Epoch 3 val loss: 0.8660, val accuracy: 0.8491\n",
            "\n",
            "=== Epoch 4/5 ===\n",
            "  step 10/510, loss=0.6887, accuracy=0.8680\n",
            "  step 20/510, loss=0.7887, accuracy=0.8559\n",
            "  step 30/510, loss=0.7698, accuracy=0.8661\n",
            "  step 40/510, loss=0.7510, accuracy=0.8565\n",
            "  step 50/510, loss=0.7829, accuracy=0.8591\n",
            "  step 60/510, loss=0.7350, accuracy=0.8667\n",
            "  step 70/510, loss=0.7366, accuracy=0.8629\n",
            "  step 80/510, loss=0.6662, accuracy=0.8699\n",
            "  step 90/510, loss=0.8035, accuracy=0.8578\n",
            "  step 100/510, loss=0.7508, accuracy=0.8603\n",
            "  step 110/510, loss=0.7326, accuracy=0.8686\n",
            "  step 120/510, loss=0.7627, accuracy=0.8610\n",
            "  step 130/510, loss=0.6965, accuracy=0.8693\n",
            "  step 140/510, loss=0.8109, accuracy=0.8527\n",
            "  step 150/510, loss=0.8044, accuracy=0.8565\n",
            "  step 160/510, loss=0.7414, accuracy=0.8635\n",
            "  step 170/510, loss=0.7774, accuracy=0.8648\n",
            "  step 180/510, loss=0.7533, accuracy=0.8622\n",
            "  step 190/510, loss=0.7790, accuracy=0.8584\n",
            "  step 200/510, loss=0.6965, accuracy=0.8654\n",
            "  step 210/510, loss=0.7497, accuracy=0.8661\n",
            "  step 220/510, loss=0.7170, accuracy=0.8597\n",
            "  step 230/510, loss=0.7707, accuracy=0.8571\n",
            "  step 240/510, loss=0.7133, accuracy=0.8546\n",
            "  step 250/510, loss=0.7605, accuracy=0.8565\n",
            "  step 260/510, loss=0.8607, accuracy=0.8438\n",
            "  step 270/510, loss=0.6771, accuracy=0.8782\n",
            "  step 280/510, loss=0.7600, accuracy=0.8565\n",
            "  step 290/510, loss=0.7235, accuracy=0.8616\n",
            "  step 300/510, loss=0.6701, accuracy=0.8724\n",
            "  step 310/510, loss=0.7120, accuracy=0.8699\n",
            "  step 320/510, loss=0.7293, accuracy=0.8661\n",
            "  step 330/510, loss=0.8170, accuracy=0.8527\n",
            "  step 340/510, loss=0.8051, accuracy=0.8533\n",
            "  step 350/510, loss=0.8602, accuracy=0.8552\n",
            "  step 360/510, loss=0.7309, accuracy=0.8654\n",
            "  step 370/510, loss=0.7146, accuracy=0.8680\n",
            "  step 380/510, loss=0.8071, accuracy=0.8540\n",
            "  step 390/510, loss=0.7204, accuracy=0.8622\n",
            "  step 400/510, loss=0.7277, accuracy=0.8686\n",
            "  step 410/510, loss=0.6868, accuracy=0.8718\n",
            "  step 420/510, loss=0.7845, accuracy=0.8540\n",
            "  step 430/510, loss=0.8284, accuracy=0.8418\n",
            "  step 440/510, loss=0.7654, accuracy=0.8667\n",
            "  step 450/510, loss=0.7150, accuracy=0.8673\n",
            "  step 460/510, loss=0.7192, accuracy=0.8648\n",
            "  step 470/510, loss=0.7615, accuracy=0.8661\n",
            "  step 480/510, loss=0.7480, accuracy=0.8616\n",
            "  step 490/510, loss=0.7376, accuracy=0.8616\n",
            "  step 500/510, loss=0.7377, accuracy=0.8661\n",
            "  step 510/510, loss=0.8128, accuracy=0.8603\n",
            "  >> Epoch 4 train loss: 0.7555, train accuracy: 0.8610\n",
            "  >> Epoch 4 val loss: 0.8522, val accuracy: 0.8523\n",
            "\n",
            "=== Epoch 5/5 ===\n",
            "  step 10/510, loss=0.6175, accuracy=0.8782\n",
            "  step 20/510, loss=0.6728, accuracy=0.8744\n",
            "  step 30/510, loss=0.7440, accuracy=0.8616\n",
            "  step 40/510, loss=0.6569, accuracy=0.8744\n",
            "  step 50/510, loss=0.6791, accuracy=0.8661\n",
            "  step 60/510, loss=0.6459, accuracy=0.8769\n",
            "  step 70/510, loss=0.6276, accuracy=0.8814\n",
            "  step 80/510, loss=0.7153, accuracy=0.8597\n",
            "  step 90/510, loss=0.7074, accuracy=0.8642\n",
            "  step 100/510, loss=0.5802, accuracy=0.8865\n",
            "  step 110/510, loss=0.7644, accuracy=0.8610\n",
            "  step 120/510, loss=0.6994, accuracy=0.8699\n",
            "  step 130/510, loss=0.6768, accuracy=0.8648\n",
            "  step 140/510, loss=0.7173, accuracy=0.8750\n",
            "  step 150/510, loss=0.6532, accuracy=0.8769\n",
            "  step 160/510, loss=0.6716, accuracy=0.8712\n",
            "  step 170/510, loss=0.7191, accuracy=0.8597\n",
            "  step 180/510, loss=0.6045, accuracy=0.8795\n",
            "  step 190/510, loss=0.8137, accuracy=0.8495\n",
            "  step 200/510, loss=0.6705, accuracy=0.8686\n",
            "  step 210/510, loss=0.7385, accuracy=0.8673\n",
            "  step 220/510, loss=0.6966, accuracy=0.8673\n",
            "  step 230/510, loss=0.8029, accuracy=0.8533\n",
            "  step 240/510, loss=0.6851, accuracy=0.8693\n",
            "  step 250/510, loss=0.7150, accuracy=0.8693\n",
            "  step 260/510, loss=0.6867, accuracy=0.8680\n",
            "  step 270/510, loss=0.7089, accuracy=0.8693\n",
            "  step 280/510, loss=0.7388, accuracy=0.8648\n",
            "  step 290/510, loss=0.6290, accuracy=0.8744\n",
            "  step 300/510, loss=0.7066, accuracy=0.8673\n",
            "  step 310/510, loss=0.6387, accuracy=0.8712\n",
            "  step 320/510, loss=0.6996, accuracy=0.8597\n",
            "  step 330/510, loss=0.6800, accuracy=0.8603\n",
            "  step 340/510, loss=0.6584, accuracy=0.8744\n",
            "  step 350/510, loss=0.7318, accuracy=0.8584\n",
            "  step 360/510, loss=0.7455, accuracy=0.8616\n",
            "  step 370/510, loss=0.6177, accuracy=0.8833\n",
            "  step 380/510, loss=0.7196, accuracy=0.8648\n",
            "  step 390/510, loss=0.7490, accuracy=0.8591\n",
            "  step 400/510, loss=0.6970, accuracy=0.8718\n",
            "  step 410/510, loss=0.7394, accuracy=0.8610\n",
            "  step 420/510, loss=0.6940, accuracy=0.8680\n",
            "  step 430/510, loss=0.6855, accuracy=0.8699\n",
            "  step 440/510, loss=0.7645, accuracy=0.8591\n",
            "  step 450/510, loss=0.7260, accuracy=0.8654\n",
            "  step 460/510, loss=0.6953, accuracy=0.8699\n",
            "  step 470/510, loss=0.7577, accuracy=0.8546\n",
            "  step 480/510, loss=0.7893, accuracy=0.8571\n",
            "  step 490/510, loss=0.6787, accuracy=0.8648\n",
            "  step 500/510, loss=0.7038, accuracy=0.8622\n",
            "  step 510/510, loss=0.6726, accuracy=0.8718\n",
            "  >> Epoch 5 train loss: 0.7003, train accuracy: 0.8679\n",
            "  >> Epoch 5 val loss: 0.8516, val accuracy: 0.8530\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "embedding_dimension = 128\n",
        "encoder_units = 256\n",
        "decoder_units = 256\n",
        "learning_rate = 1e-3\n",
        "batch = 32\n",
        "epoch = 5\n",
        "\n",
        "# Build and summarize the model\n",
        "pgn_model = build_and_summarize_model(\n",
        "    vocab_size=max_vocab_size,\n",
        "    embed_dim=embedding_dimension,\n",
        "    enc_units=encoder_units,\n",
        "    dec_units=decoder_units,\n",
        "    max_enc_len=max_input_length,\n",
        "    max_dec_len=max_summary_length\n",
        ")\n",
        "\n",
        "# Initialize the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Start training\n",
        "print(f\"\\nStarting training with Pointer-Generator + Coverage (custom loop) ...\\n\")\n",
        "train_epochs(\n",
        "    model=pgn_model,\n",
        "    optimizer=optimizer,\n",
        "    X_train=X_train,\n",
        "    Y_train=Y_train,\n",
        "    X_val=X_val,\n",
        "    Y_val=Y_val,\n",
        "    epochs=epoch,\n",
        "    batch_size=batch\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0GM6_TBLTu9"
      },
      "source": [
        "---\n",
        "## Evaluation\n",
        "Let's evaluate the model. For decoding, we will use beam search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "951MYBjOcx2l"
      },
      "outputs": [],
      "source": [
        "# Beam search decoding\n",
        "def beam_search_decode(model, enc_input, tokenizer, beam_width=4, max_dec_steps=60):\n",
        "    \"\"\"\n",
        "    enc_input: shape (1, max_enc_len)\n",
        "    Return list of token IDs for best summary\n",
        "    \"\"\"\n",
        "    # Encode\n",
        "    enc_outputs, enc_h, enc_c = model.call_encoder(enc_input)\n",
        "    coverage = tf.zeros(shape=(1, model.max_enc_len))\n",
        "\n",
        "    # Start token\n",
        "    sos_id = tokenizer.word_index.get('<sos>', 1)\n",
        "    eos_id = tokenizer.word_index.get('<eos>', 2)\n",
        "\n",
        "    initial_beam = (0.0, enc_h, enc_c, coverage, [sos_id])\n",
        "    beams = [initial_beam]\n",
        "\n",
        "    for _ in range(max_dec_steps):\n",
        "        new_beams = []\n",
        "        for logp, h, c, cov, tokens in beams:\n",
        "            if tokens[-1] == eos_id:\n",
        "                # Already ended\n",
        "                new_beams.append((logp, h, c, cov, tokens))\n",
        "                continue\n",
        "\n",
        "            x_t = tf.constant(tokens[-1], shape=(1,))  # (1,)\n",
        "            final_dist, new_h, new_c, new_cov = model.decode_step(\n",
        "                x_t, h, c, cov, enc_outputs, enc_input\n",
        "            )\n",
        "            final_dist = final_dist[0].numpy()  # => shape (vocab_size,)\n",
        "\n",
        "            # topk\n",
        "            top_ids = np.argsort(final_dist)[-beam_width:]\n",
        "            for tid in top_ids:\n",
        "                prob = final_dist[tid]\n",
        "                new_logp = logp + np.log(prob + 1e-9)\n",
        "                new_beams.append((new_logp, new_h, new_c, new_cov, tokens+[tid]))\n",
        "\n",
        "        # Sort\n",
        "        new_beams.sort(key=lambda x: x[0], reverse=True)\n",
        "        beams = new_beams[:beam_width]\n",
        "\n",
        "    return beams[0][-1]  # best tokens\n",
        "\n",
        "def ids_to_text(ids_, tokenizer):\n",
        "    rev_dict = {v:k for k,v in tokenizer.word_index.items()}\n",
        "    words = []\n",
        "    for i in ids_:\n",
        "        if i==0: break\n",
        "        w = rev_dict.get(i, '<UNK>')\n",
        "        if w in ['<sos>', '<eos>', '<UNK>']:\n",
        "            continue\n",
        "        words.append(w)\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, evaluate the model with ROUGE metric"
      ],
      "metadata": {
        "id": "taY8OA5_9Vef"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "F4-7LrQJa3Jt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b0d06d5-332f-4ab4-95b5-a7d84ad62624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=54361ece3ed788cef0f7637a4d66508951f091a8bf84f24420ee12fb2a39f3ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install rouge-score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer"
      ],
      "metadata": {
        "id": "HW_2RYAG899Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BEAM_WIDTH        = 4\n",
        "MAX_DEC_STEPS     = 60   # for beam search"
      ],
      "metadata": {
        "id": "Sm62lwgzMQ0q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate with ROUGE metric"
      ],
      "metadata": {
        "id": "9kohPuu44HMI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5B9Ofa6TL6IB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "462b3ad1-cd57-464a-d209-adc3260b7d94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating on a small sample from test data with beam search ...\n",
            "\n",
            "Sample Reference: sos riot police hooded youths clash in paris at labor reform protest eos\n",
            "Sample Prediction: protest with protest in paris protest reforms eos\n",
            "\n",
            "Sample Reference: sos trump fires campaign manager in shakeup for election push eos\n",
            "Sample Prediction: trump fired campaign manager who helped appeal to appeal eos\n",
            "\n",
            "Sample Reference: sos venezuela vp makes clearest indication yet that maduro will run in 2018 eos\n",
            "Sample Prediction: venezuela says hopes nicolas maduro will be reelected as president eos\n",
            "\n",
            "Sample Reference: sos u s lawmakers say afghanistan corruption threatens future spending eos\n",
            "Sample Prediction: u s senators seek corruption in afghanistan eos\n",
            "\n",
            "Sample Reference: sos white house names new energy climate adviser at national security council eos\n",
            "Sample Prediction: white house named new adviser to obama climate adviser spokesman eos\n",
            "\n",
            "Sample Reference: sos white house says trump will announce fed chair pick next week eos\n",
            "Sample Prediction: trump to announce next week for next week white house spokeswoman eos\n",
            "\n",
            "Sample Reference: sos president says switching china ties not diplomacy eos\n",
            "Sample Prediction: panama decision to ditch longstanding ties with taiwan eos\n",
            "\n",
            "Sample Reference: sos senate democrats delay committee votes on sessions mnuchin price eos\n",
            "Sample Prediction: senate democrats postponed votes on cabinet nominees eos\n",
            "\n",
            "Sample Reference: sos young girl who tweeted from aleppo asks trump to help syrian children eos\n",
            "Sample Prediction: syrian girl twitter updates from aleppo eos\n",
            "\n",
            "Sample Reference: sos russian presidential hopeful says she wont sling mud at putin eos\n",
            "Sample Prediction: russian tv personality planning to run against putin eos\n",
            "\n",
            "Sample Reference: sos myanmars suu kyi working to get aid to rohingya mcconnell eos\n",
            "Sample Prediction: mcconnell says he had spoken with myanmar suu kyi eos\n",
            "\n",
            "Sample Reference: sos u s will not give exxon permission to drill in russia eos\n",
            "Sample Prediction: u s will not make exception for american companies eos\n",
            "\n",
            "Sample Reference: sos pope priests in bangladesh ahead of meeting with rohingya eos\n",
            "Sample Prediction: pope to new priests rohingya from bangladesh eos\n",
            "\n",
            "Sample Reference: sos eus juncker courts eurosceptic with dinner invite eos\n",
            "Sample Prediction: juncker says invited leaders to ease tensions eos\n",
            "\n",
            "Sample Reference: sos judge to weigh citizens bridgegate complaint against new jerseys christie eos\n",
            "Sample Prediction: new jersey judge plans to decide by bridgegate complaint eos\n",
            "\n",
            "Sample Reference: sos putin says trump is listening to russias views on north korea crisis eos\n",
            "Sample Prediction: putin says trump was listening to russia on north korean missile crisis eos\n",
            "\n",
            "Sample Reference: sos juncker calls on europe to reject separatist poison amid catalonia crisis eos\n",
            "Sample Prediction: juncker urges europe to stand up against catalan independence push eos\n",
            "\n",
            "Sample Reference: sos australias turnbull goes rural in a cabinet reshuffle aimed at widening appeal eos\n",
            "Sample Prediction: australian minister says new attorney general will bolster flagging popularity eos\n",
            "\n",
            "Sample Reference: sos louisiana governor says states finances in dire situation eos\n",
            "Sample Prediction: louisiana governor says picture of budget cuts eos\n",
            "\n",
            "Sample Reference: sos trump seeks input from u s energy companies on paris climate pact eos\n",
            "Sample Prediction: u s energy companies contacting u s energy climate deal eos\n",
            "\n",
            "Sample Reference: sos north korean threat highlights nato missile shield weak link eos\n",
            "Sample Prediction: nato says nato diplomatic efforts to stop north korea eos\n",
            "\n",
            "Sample Reference: sos ftc official is trump favorite for chief source eos\n",
            "Sample Prediction: trumps choice to run the\n",
            "\n",
            "Sample Reference: sos philippine ombudsman files criminal case against expresident aquino eos\n",
            "Sample Prediction: philippines antigraft body filed for mishandling raid eos\n",
            "\n",
            "Sample Reference: sos white house voices concerns on senate sept 11 lawsuit bill eos\n",
            "Sample Prediction: white house says serious concerns about senate bill eos\n",
            "\n",
            "Sample Reference: sos trump says trade gap will make china meeting a very difficult one eos\n",
            "Sample Prediction: trump set tone for tense first meeting with xi eos\n",
            "\n",
            "Sample Reference: sos trump rallies gun owners with fiery speech eos\n",
            "Sample Prediction: trump gun owners to bear arms and arms and zones eos\n",
            "\n",
            "Sample Reference: sos honduran army enforces curfew after vote count stalls eos\n",
            "Sample Prediction: honduran security forces to enforce curfew curfew eos\n",
            "\n",
            "Sample Reference: sos u s calls myanmar moves against rohingya ethnic cleansing eos\n",
            "Sample Prediction: u s says myanmar military operation against rohingya population eos\n",
            "\n",
            "Sample Reference: sos germanys steinmeier warns of eu disruptions in event of brexit eos\n",
            "Sample Prediction: eu would not simply carry on as should leave the\n",
            "\n",
            "Sample Reference: sos how to get sick on the u s campaign trail little sleep bad food everywhere eos\n",
            "Sample Prediction: clintons bout of light on travel bad food campaign eos\n",
            "\n",
            "Sample Reference: sos cnn says its reports on trump intel documents different from eos\n",
            "Sample Prediction: trump cnn news division of time warner inc eos\n",
            "\n",
            "Sample Reference: sos u s lawmakers want response to north korea nuclear tests eos\n",
            "Sample Prediction: u s lawmakers seek response to north korea eos\n",
            "\n",
            "Sample Reference: sos clinton sanders for role as antitrump candidate eos\n",
            "Sample Prediction: clinton sanders in wisconsin over full force eos\n",
            "\n",
            "Sample Reference: sos vote on gun control measures in senate likely on tuesday feinstein eos\n",
            "Sample Prediction: california vote on gun control measures in u s senate vote eos\n",
            "\n",
            "Sample Reference: sos north korea to release captured south korea fishing boat friday kcna eos\n",
            "Sample Prediction: north korean fishing will release south korean fishing vessel eos\n",
            "\n",
            "Sample Reference: sos u n ban on north korean textiles will disrupt industry and ordinary lives experts say eos\n",
            "Sample Prediction: u n sanctions on north korea to disrupt north korea eos\n",
            "\n",
            "Sample Reference: sos trump names cheryl acting chairman of ferc eos\n",
            "Sample Prediction: trump named cheryl as acting chairman of acting chairman eos\n",
            "\n",
            "Sample Reference: sos trump father of ucla player in case is fool eos\n",
            "Sample Prediction: trump reignited feud with ucla father of ucla father eos\n",
            "\n",
            "Sample Reference: sos eu border controls could be extended in crisis commission says eos\n",
            "Sample Prediction: eu border border could be extended for up years eos\n",
            "\n",
            "Sample Reference: sos fbi has sufficient resources for russia investigation mccabe eos\n",
            "Sample Prediction: fbis acting head says he is not aware of russian interference eos\n",
            "\n",
            "Sample Reference: sos royal jordanian gets u s instructions lifting travel ban eos\n",
            "Sample Prediction: u n airline royal jordanian received instructions from syria eos\n",
            "\n",
            "Sample Reference: sos illinois governor orders special session to break budget impasse eos\n",
            "Sample Prediction: illinois governor says ordered to return to budget eos\n",
            "\n",
            "Sample Reference: sos microsoft looks at whether russians bought u s ads on search engine eos\n",
            "Sample Prediction: microsoft looking into whether russians on search engine ads eos\n",
            "\n",
            "Sample Reference: sos obama vietnam on rights after activists stopped from meeting him eos\n",
            "Sample Prediction: vietnam vietnam vietnam on political freedoms after critics eos\n",
            "\n",
            "Sample Reference: sos u s republicans ax disclosure emissions rules on energy eos\n",
            "Sample Prediction: u s republicans want obamaera financial ties eos\n",
            "\n",
            "Sample Reference: sos israel orders deportation of two turks after jerusalem arrests eos\n",
            "Sample Prediction: israel says deportation of three turks briefly arrested eos\n",
            "\n",
            "Sample Reference: sos japan pm says u n sanctions on north korea must be firmly imposed eos\n",
            "Sample Prediction: abe sanctions on north korea needed to be firmly abe eos\n",
            "\n",
            "Sample Reference: sos cuba breaks up weekly dissident march hours before obama visit eos\n",
            "Sample Prediction: cuban police fire by hundreds of dissident visit eos\n",
            "\n",
            "Sample Reference: sos tech billionaire thiel says trump movement not going away eos\n",
            "Sample Prediction: trump thiel to carry on even if trump bid for white house eos\n",
            "\n",
            "Sample Reference: sos judge warns attorneys for manafort and gates against speaking on case out of court eos\n",
            "Sample Prediction: u s judge orders lawyers for trumps presidential campaign eos\n",
            "\n",
            "Sample Reference: sos iraq syria converge on islamic states last strongholds eos\n",
            "Sample Prediction: iraqi forces attack attack to drive islamic state eos\n",
            "\n",
            "Sample Reference: sos trump netanyahu with and a jolt or two eos\n",
            "Sample Prediction: trump taps netanyahu of of first time eos\n",
            "\n",
            "Sample Reference: sos u s house speaker ryan renews call to suspend classified briefings for clinton eos\n",
            "Sample Prediction: house speaker ryan renewed call for clinton eos\n",
            "\n",
            "Sample Reference: sos russias putin pulling no surprises says hell seek reelection eos\n",
            "Sample Prediction: putin worst kept political secret on 2018 eos\n",
            "\n",
            "Sample Reference: sos fcc chairman expected to unveil strategy to reverse net neutrality sources eos\n",
            "Sample Prediction: fcc expected to unveil strategy this net neutrality eos\n",
            "\n",
            "Sample Reference: sos japans slide into war in emperor memoir eos\n",
            "Sample Prediction: japan emperor did not veto his war on war campaign eos\n",
            "\n",
            "Sample Reference: sos alabama senate candidate moore calls allegations dirty politics eos\n",
            "Sample Prediction: embattled republican senate candidate roy misconduct allegations eos\n",
            "\n",
            "Sample Reference: sos trump says was being sarcastic in russia hack comments eos\n",
            "Sample Prediction: trump emails tried to quell furor over russia emails eos\n",
            "\n",
            "Sample Reference: sos u s urges myanmar to address rights abuse allegations eos\n",
            "Sample Prediction: tillerson says myanmar leader san suu kyi to facilitate humanitarian aid eos\n",
            "\n",
            "Sample Reference: sos canada over possible huge surge in asylumseekers sources eos\n",
            "Sample Prediction: canada fears in asylum seekers at canada border eos\n",
            "\n",
            "Sample Reference: sos extrump staffer sues campaign alleges gun incident in north carolina eos\n",
            "Sample Prediction: north carolina staffer suing trumps presidential campaign eos\n",
            "\n",
            "Sample Reference: sos former intelligence chief clapper comey was uneasy with trump dinner msnbc eos\n",
            "Sample Prediction: national intelligence clapper says uneasy with comey dinner eos\n",
            "\n",
            "Sample Reference: sos violence flares at protest near u s embassy in lebanon eos\n",
            "Sample Prediction: lebanese security forces fired tear gas and water eos\n",
            "\n",
            "Sample Reference: sos exclusive trump administration reduces support for prisoner halfway houses eos\n",
            "Sample Prediction: trump has been cutting support for halfway houses contracts eos\n",
            "\n",
            "Sample Reference: sos factbox facts about conservative activist schlafly eos\n",
            "Sample Prediction: u s conservative activist schlafly on 92 eos\n",
            "\n",
            "Sample Reference: sos rights group accuses myanmar of crimes against humanity eos\n",
            "Sample Prediction: u s sanctions crimes crimes against muslim insurgents eos\n",
            "\n",
            "Sample Reference: sos democrats set bills seeking to overturn trump travel ban eos\n",
            "Sample Prediction: senators to force vote on bill to rescind travel bill eos\n",
            "\n",
            "Sample Reference: sos london mayor calls on british foreign minister johnson to resign eos\n",
            "Sample Prediction: london mayor says british foreign minister to resign eos\n",
            "\n",
            "Sample Reference: sos kenyas parliament takes threeweek break at request eos\n",
            "Sample Prediction: deadlock to unscheduled threeweek recess eos\n",
            "\n",
            "Sample Reference: sos u s womens open must leave trump national says eos\n",
            "Sample Prediction: fourteen years for fourteen open to be moved to trump eos\n",
            "\n",
            "Sample Reference: sos u s house to weigh 622 1 million in new zika funding eos\n",
            "Sample Prediction: u s house will try to pass zika bill eos\n",
            "\n",
            "Sample Reference: sos russia says progress made towards cooperation on disputed islands eos\n",
            "Sample Prediction: russian foreign minister says progress on measures eos\n",
            "\n",
            "Sample Reference: sos trump frustrated by afghan war suggests firing u s commander officials eos\n",
            "Sample Prediction: u s military doubts about war in afghanistan eos\n",
            "\n",
            "Sample Reference: sos trump pledge from boeing on air force one costs eos\n",
            "Sample Prediction: trump extracted promise of boeing air force eos\n",
            "\n",
            "Sample Reference: sos pope francis plane shifts course to avoid hurricane irma eos\n",
            "Sample Prediction: pope says puerto rico headed for colombia plane forced eos\n",
            "\n",
            "Sample Reference: sos u s and cuba to sign aviation pact on feb 16 eos\n",
            "Sample Prediction: u s officials to travel to havana on feb 16 aviation pact eos\n",
            "\n",
            "Sample Reference: sos senegal rebels issue warning over mineral sands mine eos\n",
            "Sample Prediction: rebel movement for war eos\n",
            "\n",
            "Sample Reference: sos frances macron calls lebanons aoun over pm resignation office eos\n",
            "Sample Prediction: macron tells aoun to discuss developments in saudi arabia eos\n",
            "\n",
            "Sample Reference: sos china russia to hold simulated antimissile drill eos\n",
            "Sample Prediction: chinese militaries to next month hold antimissile drills eos\n",
            "\n",
            "Sample Reference: sos israeli minister expresses concern over u s saudi arms deal eos\n",
            "Sample Prediction: israel muted concern to a major arms deal eos\n",
            "\n",
            "Sample Reference: sos coalition of 24 states urges trump to kill obamas carbon emission plan eos\n",
            "Sample Prediction: trump says u s trump to kill the\n",
            "\n",
            "Sample Reference: sos zimbabwes vp is safe traveling to south africa ally eos\n",
            "Sample Prediction: mnangagwa who fired by mugabe will travel to south africa eos\n",
            "\n",
            "Sample Reference: sos democrats seek probe of trump donation to florida attorney general eos\n",
            "Sample Prediction: florida democrats approve donation made by trump foundation eos\n",
            "\n",
            "Sample Reference: sos u s senator says panel could take up russia sanctions bill this summer eos\n",
            "Sample Prediction: u s senate panel could take up bill on russia sanctions eos\n",
            "\n",
            "Sample Reference: sos hot air u s gas exporters rush to sell lng to china eos\n",
            "Sample Prediction: u s gas exporters to grab bigger china eos\n",
            "\n",
            "Sample Reference: sos trump backs new york in battle for saudi aramco listing eos\n",
            "Sample Prediction: trump saudi arabia to list national oil company eos\n",
            "\n",
            "Sample Reference: sos turkeys erdogan says critical decisions on syria will be made today eos\n",
            "Sample Prediction: erdogan says critical decisions to be taken for syrian crisis eos\n",
            "\n",
            "Sample Reference: sos u s attorney general still deciding whether to impose reforms on chicago police eos\n",
            "Sample Prediction: sessions says would seek to impose reforms on chicago police eos\n",
            "\n",
            "Sample Reference: sos brazil pension vote put off until february eos\n",
            "Sample Prediction: brazil congress to delay vote on social security benefits eos\n",
            "\n",
            "Sample Reference: sos china calls for advancing free trade talks with south korea japan eos\n",
            "Sample Prediction: chinese premier calls for free trade talks talks xinhua eos\n",
            "\n",
            "Sample Reference: sos trump to host norways solberg on jan 10 white house says eos\n",
            "Sample Prediction: trump to host norway solberg in washington next month eos\n",
            "\n",
            "Sample Reference: sos bounce for australian pm as voters tire of leadership eos\n",
            "Sample Prediction: embattled australian minister says unexpected boost poll eos\n",
            "\n",
            "Sample Reference: sos greece considers extradition of bitcoin fraud suspect wanted by u s and russia eos\n",
            "Sample Prediction: russian cybercrime suspect says nothing to do with moneylaundering operation eos\n",
            "\n",
            "Sample Reference: sos house speaker ryan says trump should not rescind immigration program eos\n",
            "Sample Prediction: house speaker ryan says trump should not rescind obamaera program eos\n",
            "\n",
            "Sample Reference: sos cambodias hun sen calls for closure of rights group founded by rival eos\n",
            "Sample Prediction: cambodian hun sen calls for closure of rights groups eos\n",
            "\n",
            "Sample Reference: sos trump campaign paid lawyer now representing son 50 000 in june eos\n",
            "Sample Prediction: trumps campaign paid 50 000 law before trump jr eos\n",
            "\n",
            "Sample Reference: sos philippines vows fair probe after vietnamese fishermen killed eos\n",
            "Sample Prediction: philippines says vietnam of fair and fair investigation eos\n",
            "\n",
            "Sample Reference: sos poland will not change its stance on eus posted workers directive pm eos\n",
            "Sample Prediction: poland to not change stance on european stance on stance eos\n",
            "\n",
            "Sample Reference: sos mccain once by trump hands him big defeat in healthcare vote eos\n",
            "Sample Prediction: the\n",
            "\n",
            "Sample Reference: sos hammond says uk very close to deal on eu citizens rights eos\n",
            "Sample Prediction: eu says very close to protect rights of rights eos\n",
            "\n",
            "Average over 100 samples:\n",
            "  ROUGE-1: 0.4363114170161014\n",
            "  ROUGE-2: 0.16744780268564088\n",
            "  ROUGE-L: 0.41367119107541767\n"
          ]
        }
      ],
      "source": [
        "def evaluate_rouge(model, X_data, Y_data, tokenizer, num_samples=5):\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1','rouge2','rougeL'], use_stemmer=True)\n",
        "    idxs = np.random.choice(len(X_data), size=min(num_samples, len(X_data)), replace=False)\n",
        "\n",
        "    r1_list, r2_list, rl_list = [], [], []\n",
        "    for idx in idxs:\n",
        "        enc_input = X_data[idx:idx+1]\n",
        "        ref_ids   = Y_data[idx]\n",
        "        ref_text  = ids_to_text(ref_ids, tokenizer)\n",
        "\n",
        "        pred_ids  = beam_search_decode(model, enc_input, tokenizer, beam_width=BEAM_WIDTH, max_dec_steps=MAX_DEC_STEPS)\n",
        "        pred_text = ids_to_text(pred_ids, tokenizer)\n",
        "\n",
        "        scores = scorer.score(ref_text, pred_text)\n",
        "        r1_list.append(scores['rouge1'].fmeasure)\n",
        "        r2_list.append(scores['rouge2'].fmeasure)\n",
        "        rl_list.append(scores['rougeL'].fmeasure)\n",
        "\n",
        "        print(\"\\nSample Reference:\", ref_text)\n",
        "        print(\"Sample Prediction:\", pred_text)\n",
        "\n",
        "    print(f\"\\nAverage over {len(r1_list)} samples:\")\n",
        "    print(\"  ROUGE-1:\", np.mean(r1_list))\n",
        "    print(\"  ROUGE-2:\", np.mean(r2_list))\n",
        "    print(\"  ROUGE-L:\", np.mean(rl_list))\n",
        "\n",
        "# Let’s do a small test\n",
        "print(\"\\nEvaluating on a small sample from test data with beam search ...\")\n",
        "evaluate_rouge(pgn_model, X_test, Y_test, tokenizer, num_samples=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Analysis\n",
        "**ROUGE-1 (0.4363):**\n",
        "- Approximately 43.6% of the unigrams in the generated summaries overlap with those in the reference summaries.\n",
        "- This score indicates a moderate level of word overlap. While it shows that the model is capturing a significant portion of relevant content, there's room for improvement in terms of capturing more key terms and ensuring comprehensive coverage of the source material.\n",
        "\n",
        "**ROUGE-2 (0.1674):**\n",
        "- Around 16.7% of the bigrams in the generated summaries match those in the reference summaries.\n",
        "- Bigram overlap is typically lower than unigram overlap because it captures more specific phrases and context. A ROUGE-2 score of 0.1674 suggests that the model has some ability to maintain contextual and sequential accuracy but may struggle with maintaining fluency and preserving the original meaning in phrases.\n",
        "\n",
        "**ROUGE-L (0.4137):**\n",
        "- Approximately 41.4% of the longest common subsequence between the generated and reference summaries is preserved.\n",
        "- ROUGE-L is sensitive to the overall structure and coherence of the summary. A score of 0.4137 indicates that the model maintains a reasonable level of structural similarity to the reference summaries, suggesting that it can generate coherent and logically ordered content, albeit not perfectly.\n",
        "\n",
        "**The best avarage that we get was**\n",
        "\n",
        "  ROUGE-1: 0.48847994111152004\n",
        "\n",
        "  ROUGE-2: 0.16705882352941176\n",
        "\n",
        "  ROUGE-L: 0.45491350754508647\n",
        "\n"
      ],
      "metadata": {
        "id": "ovQPCTZK1nCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Contributors\n",
        "Faruk KAPLAN - 21050111026\n",
        "\n",
        "Mert ALTEKİN - 21050111065"
      ],
      "metadata": {
        "id": "iwJmT2lj2evb"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}